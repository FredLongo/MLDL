{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ku5zo0Cg-riNcjcXDhtJOpifzBWu-QrB",
      "authorship_tag": "ABX9TyNn+XHN2LXBVltmldAYTkkF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FredLongo/MLDL/blob/main/CNN_Model_to_Train_Touching_R2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fred Longo, Modeling after notebook:\n",
        "\n",
        "https://www.kaggle.com/code/shuvojitdas/emotion-detection-using-cnn/notebook"
      ],
      "metadata": {
        "id": "9NX5Z9yr_mTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xGdFlsE1kj-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is where the Program Starts"
      ],
      "metadata": {
        "id": "EAvaRd6AnC-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oPzVKy_G0xFl"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Import Librarys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from datetime import datetime\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.models import Model, Sequential\n",
        "#from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
        "#from keras.optimizers import adam_v2\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "#from keras.optimizers import rmsprop\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "2Hb5b8BO2-1L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting\n",
        "\n",
        "picture_size = 224\n",
        "folder_path       = \"drive/MyDrive/Databases/Dataset_Project_1/\"\n",
        "folder_path_train = \"drive/MyDrive/Databases/Dataset_Project_1/train\"\n",
        "no_of_classes = 3\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aHbAa-o63CVN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Up Data groups for Training Testing and Validation."
      ],
      "metadata": {
        "id": "y7DUXJCrodoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size  = 10\n",
        "\n",
        "'''\n",
        "# Define your ImageDataGenerator with a validation split\n",
        "datagen = ImageDataGenerator(validation_split=0.2) # for example, 20% for validation\n",
        "\n",
        "# Setup the training generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    directory=folder_path_train, # The directory where your data is located\n",
        "    target_size=(picture_size, picture_size),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training', # Set as training data\n",
        "    shuffle=True)\n",
        "\n",
        "\n",
        "# Setup the validation generator\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    directory=folder_path_train, # The directory where your data is located\n",
        "    target_size=(picture_size, picture_size),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation', # Set as validation data\n",
        "    shuffle=True)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "# Original\n",
        "\n",
        "\n",
        "datagen_train  = ImageDataGenerator()\n",
        "datagen_val = ImageDataGenerator()\n",
        "\n",
        "train_folder_path = folder_path + \"small_v\"\n",
        "validate_folder_path = folder_path + \"small_t\"\n",
        "\n",
        "train_set = datagen_train.flow_from_directory(train_folder_path,\n",
        "                                              target_size = (picture_size,picture_size),\n",
        "                                              color_mode = \"grayscale\",\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=True)\n",
        "\n",
        "\n",
        "test_set = datagen_val.flow_from_directory(validate_folder_path,\n",
        "                                              target_size = (picture_size,picture_size),\n",
        "                                              color_mode = \"grayscale\",\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B31Y86G-IDU",
        "outputId": "84d330ab-786c-4916-d77d-b26ac1d66e40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 960 images belonging to 3 classes.\n",
            "Found 960 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Model"
      ],
      "metadata": {
        "id": "9K3MOvYVouZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "#1st CNN layer\n",
        "#model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
        "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (224,224,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#2nd CNN layer\n",
        "model.add(Conv2D(128,(5,5),padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout (0.25))\n",
        "\n",
        "#3rd CNN layer\n",
        "model.add(Conv2D(512,(3,3),padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout (0.25))\n",
        "\n",
        "#4th CNN layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#Fully connected 1st layer\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# Fully connected layer 2nd layer\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(no_of_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "opt = Adam(learning_rate=0.0001)"
      ],
      "metadata": {
        "id": "finWrEwv-IAO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2utGwlZI-H9O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "uuHQyjxv-H6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ccdde0-6ce4-4055-eb90-4a27ebd9a86b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      640       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 224, 224, 64)      256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 224, 224, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 112, 112, 64)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 128)     204928    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 112, 112, 128)     512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 112, 112, 128)     0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 512)       590336    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 56, 56, 512)       2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 56, 56, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 512)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 28, 28, 512)       2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 512)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               25690368  \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28987139 (110.58 MB)\n",
            "Trainable params: 28983171 (110.56 MB)\n",
            "Non-trainable params: 3968 (15.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"./model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True\n",
        "                          )\n",
        "\n",
        "reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=3,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)\n",
        "\n",
        "callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FmBRLaCd-H3A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Start Time:\",(datetime.now()).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "steps_per_epoch = train_set.n//train_set.batch_size\n",
        "if steps_per_epoch == 0:\n",
        "    steps_per_epoch = 1\n",
        "print(steps_per_epoch)\n",
        "# Original\n",
        "\n",
        "history = model.fit_generator(generator=train_set,\n",
        "#                                steps_per_epoch=steps_per_epoch,\n",
        "                                epochs=epochs,\n",
        "                                validation_data = test_set,\n",
        "                                validation_steps = test_set.n//test_set.batch_size,\n",
        "                                callbacks=callbacks_list\n",
        "                                )\n",
        "\n",
        "\n",
        "\n",
        "print(\"End Time:\",(datetime.now()).strftime(\"%H:%M:%S\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOQJYvja-H0H",
        "outputId": "0f426560-73ac-407b-ab97-a215f63b2995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Time: 06:16:09\n",
            "96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e3e871e213d2>:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(generator=train_set,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 1.4254 - accuracy: 0.3583 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.32396, saving model to ./model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r96/96 [==============================] - 1436s 15s/step - loss: 1.4254 - accuracy: 0.3583 - val_loss: 3.5439 - val_accuracy: 0.3240 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 1.2021 - accuracy: 0.4458 \n",
            "Epoch 2: val_accuracy improved from 0.32396 to 0.33229, saving model to ./model.h5\n",
            "96/96 [==============================] - 1309s 14s/step - loss: 1.2021 - accuracy: 0.4458 - val_loss: 2.7566 - val_accuracy: 0.3323 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 1.1007 - accuracy: 0.4948 \n",
            "Epoch 3: val_accuracy improved from 0.33229 to 0.45937, saving model to ./model.h5\n",
            "96/96 [==============================] - 1450s 15s/step - loss: 1.1007 - accuracy: 0.4948 - val_loss: 1.1327 - val_accuracy: 0.4594 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 1.0173 - accuracy: 0.5385 \n",
            "Epoch 4: val_accuracy improved from 0.45937 to 0.50104, saving model to ./model.h5\n",
            "96/96 [==============================] - 1438s 15s/step - loss: 1.0173 - accuracy: 0.5385 - val_loss: 1.3341 - val_accuracy: 0.5010 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 0.9362 - accuracy: 0.5885 \n",
            "Epoch 5: val_accuracy did not improve from 0.50104\n",
            "96/96 [==============================] - 1363s 14s/step - loss: 0.9362 - accuracy: 0.5885 - val_loss: 1.6207 - val_accuracy: 0.4563 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 0.8542 - accuracy: 0.6062 \n",
            "Epoch 6: val_accuracy improved from 0.50104 to 0.56250, saving model to ./model.h5\n",
            "96/96 [==============================] - 1301s 14s/step - loss: 0.8542 - accuracy: 0.6062 - val_loss: 0.9384 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.7323 \n",
            "Epoch 7: val_accuracy improved from 0.56250 to 0.62917, saving model to ./model.h5\n",
            "96/96 [==============================] - 1337s 14s/step - loss: 0.6911 - accuracy: 0.7323 - val_loss: 0.9713 - val_accuracy: 0.6292 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 0.5804 - accuracy: 0.7656 \n",
            "Epoch 8: val_accuracy improved from 0.62917 to 0.65000, saving model to ./model.h5\n",
            "96/96 [==============================] - 1398s 15s/step - loss: 0.5804 - accuracy: 0.7656 - val_loss: 0.8556 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.8167 \n",
            "Epoch 9: val_accuracy did not improve from 0.65000\n",
            "96/96 [==============================] - 1444s 15s/step - loss: 0.4725 - accuracy: 0.8167 - val_loss: 1.3844 - val_accuracy: 0.5031 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "96/96 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.8031 \n",
            "Epoch 10: val_accuracy improved from 0.65000 to 0.65417, saving model to ./model.h5\n",
            "96/96 [==============================] - 1278s 13s/step - loss: 0.4842 - accuracy: 0.8031 - val_loss: 0.9339 - val_accuracy: 0.6542 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "20/96 [=====>........................] - ETA: 13:37 - loss: 0.3000 - accuracy: 0.8950"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "'''\n",
        "print(\"Start Time:\",(datetime.now()).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "#Modified\n",
        "\n",
        "history = model.fit(generator=train_generator,\n",
        "                                steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "                                epochs=epochs,\n",
        "                                steps_per_epoch = epochs,\n",
        "                                validation_data = validation_generator,\n",
        "                                validation_steps = validation_generator.n//validation_generator.batch_size,\n",
        "                                callbacks=callbacks_list\n",
        "                                )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"End Time:\",(datetime.now()).strftime(\"%H:%M:%S\"))\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "4433f123-0437-4f0e-9a99-615c0f97773a",
        "id": "YNbYY9l5itLL",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"Start Time:\",(datetime.now()).strftime(\"%H:%M:%S\"))\\n\\n#Modified\\n\\nhistory = model.fit(generator=train_generator,\\n                                steps_per_epoch=train_generator.n//train_generator.batch_size,\\n                                epochs=epochs,\\n                                steps_per_epoch = epochs,\\n                                validation_data = validation_generator,\\n                                validation_steps = validation_generator.n//validation_generator.batch_size,\\n                                callbacks=callbacks_list\\n                                )\\n\\n\\n\\n\\nprint(\"End Time:\",(datetime.now()).strftime(\"%H:%M:%S\"))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4djQFJ3G-HxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0gG7o0k-Htz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7IIxJDu-HqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rDhcKILS-HnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KIrXqCQs-Hg9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}